---
title: "Agentic Large Language Models, a survey, review: Interacting"
date: 2025-11-25 12:02:00 +0900
categories: [AI Agent]
tags: [AI Agent, NLP, LLM]
media_subpath: /assets/img/Agentic-Large-Language-Models,-a-survey/
---
[[paper link]](https://arxiv.org/abs/2503.23037)

Acting 파트에 이어 Interacting 파트를 정리하고자 합니다.

특정 내용에 대해 자세하게 다루기보다, "이러한 개념이 현재 활용되고 있구나"에 초점을 맞추어 리뷰합니다.

사회심리학적인 아이디어가 들어가는 부분이 많아, 개인적으로 가장 흥미롭게 읽었습니다.

__*아래 내용은 간략하게 논문을 정리한 내용입니다. 정리, 번역, 표현에는 오류가 있을 수 있습니다.*__ <br>
<br><br>
# 4. Interacting

- LLM이 다른 에이전트(인간 및 기계)와 사회적으로 상호작용하는 능력과 그로 인해 발생하는 현상에 대해 다룹니다.
- LLM은 기억 능력 과 계획 능력이 있으며, 자기 성찰 루프(Reflective loop)를 통해 주도적으로 행동할 수 있습니다.
- 이는 사용자나 다른 기계 에이전트와의 사회적 상호작용에 대한 새로운 가능성을 제시합니다.

## 4.1 Social Capabilities of LLMs

### 4.1.1 CONVERSATION

- **자연어 상호작용:** 지시 튜닝(instruction-tuned)된 LLM의 핵심 중 하나는 자연어(Natural language)를 통해 상호작용하는 능력입니다.
- 원활하고 만족스러운 상호작용을 위한 핵심 요소는 기능적(functional) , pragmatic능력, 특정 맥락에서 사용자가 무엇을 의미하고 무엇을 원하는지 이해할 수 있는 능력입니다.
- **한계:** 하지만 아직까지는 LLM이 인간과 동일한 방식으로 보고 듣고 느끼지 못하며(맥락 정보 부족), 이전 상호작용에 대한 지식이 없습니다.
- **공감과 예절:** LLM은 대화 속에서 정서적 상태를 감지하고, 이를 상호작용에 반영하여 공감하는 대화 파트너가 될 수 있습니다. 또한, 사회적 예절(etiquette)을 지키는 기계는 인간에게 더 신뢰받는 경향이 있습니다 .
<br>
### 4.1.2 STRATEGIC BEHAVIOR

- **전략적 행동 연구:** 게임 이론적 상황에서 LLM의 행동이, 다른 아키텍처나 인간과 어떻게 다른지 연구되고 있습니다.
- **게임 유형별 성능:** LLM은 죄수의 딜레마(Prisoner's Dilemma)와 같이 자신의 이익을 추구하는 것이 유리한 게임에서는 특히 잘하지만, 조정(coordination)이 필요한 게임은 잘 못합니다.
- **추상적 추론 vs 맥락적 프레이밍:** [Lorè and Heydari 2023]는 게임 구조에 따른 최적 전략을 결정하는 추상적 전략 추론 능력과, "당신은 외교관입니다"와 같은 맥락적 프레이밍에 대한 반응성을 구분하여 연구를 진행했습니다.
  연구 결과, LLaMa-2와 GPT-4는 추상적 추론 능력이 높은 반면, GPT-3.5는 추상적 추론 능력은 낮고 맥락적 프레이밍에 매우 민감한 것으로 나타났습니다.
- **모델 간 비교:** 일반적으로 오픈소스 LLM(LLaMa 등)은 상용 LLM(GPT-4)보다 복잡한 게임 관련 경쟁력이 떨어집니다.
- **관점의 중요성:** [Hou et al., 2024] 연구에서 LLM은 3인칭 시점보다 1인칭 시점으로 작동할 때 마음 이론(Theory of Mind) 추론 능력이 향상되는 것으로 나타났습니다.
- **EgoSocialArena**: 인지적, 상황적, 행동적 지능에 초점을 맞춘 벤치마크입니다[Hou et al., 2024].

![image.png](image%2020.png)
<br>
### 4.1.3 THEORY OF MIND

- **Theory of Mind:** 타인의 정신 상태를 추론하고 그들의 관점에서 세상을 이해하는 것입니다 .
- **LLM과 Theory of Mind:** 마음 이론은 LLM의 계획(Planning) 및 자기 성찰(Self Reflection)과 관련이 있으며, 사회적 판단을 내리고 상호작용의 미래 단계를 계획하는 데 도움을 줍니다.
- **초기 논쟁:** 초기 실험에서는 LLM이 Theory of Mind 테스트를 통과하는 것으로 나타나, 마음 이론이 자연스럽게 학습된다는 주장이 제기되었습니다.
- **벤치마크 및 발전:** 이후 더 구체적인 마음 이론 벤치마크들이 도입되었고(ToMBench 등), 멀티모달 통합, 인간 성능과의 직접 비교 등 다양한 연구가 진행되고 있습니다.
- **사회적 판단:** Theory of Mind의 응용 분야 중 하나는 사회적 판단입니다. 연구에 따르면 LLM은 사회적 상황 판단 과제에서 인간 점수를 능가하는 성능을 보여주기도 합니다.
<br><br>
## 4.2. Role-Based Interaction

- **새로운 가능성:** AI 에이전트는 자연어로 소통할 수 있어 기존 시뮬레이션의 한계를 극복하고, 게임 이론, 역할 기반 상호작용, 팀워크 분야에서 새로운 영역 탐구에 활용될 수 있습니다.
<br>
### 4.2.1 STRATEGIC BEHAVIOR IN MULTI-LLM ENVIRONMENTS

- **MAgIC:** 사회적 추론 게임(Undercover, Chameleon)과 게임 이론적 시나리오(비용 분담, 죄수의 딜레마 등)를 사용하여 합리성, 판단력, 기만, 협력 등의 7가지 핵심 능력을 평가하기도 하였습니다[Xu et al., 2024a].

![image.png](image%2021.png)

- **GAMA-Bench:** 다양한 다중 에이전트 게임(경매, 협상, 죄수의 딜레마 등)을 포함하는 벤치마크입니다.
- **Alympics:** 복잡하고 전략적인 다중 에이전트 문제를 위한 플랫폼으로, LLM 기반 에이전트와의 인간 유사 전략적 상호작용을 시뮬레이션할 수 있는 통제된 놀이터를 제공합니다.
- **AucArena:** 경매 상황을 시뮬레이션하며, GPT-4와 같은 모델이 예산 관리 및 목표 집중과 같은 기술을 보유하고 있음을 보여줍니다.

![image.png](image%2022.png)
<br>
### 4.2.2 ROLE-BASED TASK SOLVING AND TEAM WORK

- **역할 할당:** LLM은 창작자-비평가(creator-critic) 또는 관리자-작업자(manager-worker)와 같이 상호 보완적인 역할을 맡아 쌍이나 팀으로 작업을 수행할 수 있습니다. 각 에이전트는 고유한 목표를 가지고 대화를 통해 협력하여 문제를 해결합니다.
- **CAMEL 프레임워크:** 두 개의 LLM이 사전 정의된 역할(예: 주식 거래자와 Python 프로그래머)을 맡아 협력하는 프레임워크입니다.

    
    ![image.png](image%2023.png)
    

- **인셉션 프롬프팅:** 인셉션 프롬프팅(Inception Prompting)과 역할 설명을 통해 에이전트는 캐릭터를 유지하며 대화를 통해 복잡한 문제를 관리 가능한 단계로 세분화하여 목표를 향해 협력합니다.
- **토론과 논쟁:** LLM 간의 토론이나 논쟁을 활용하여 추론과 작업 성능을 향상시키는 연구도 진행되었습니다.
- **Multi-Agent Debate:** [Du et al. 2024]은 여러 LLM이 답변을 제안하고 서로의 추론을 비판하는 여러 라운드의 토론을 거칠 때, 더 정확한 답변에 도달함을 보여주었습니다.
- **Society of Minds:** 민스키(Minsky)의 'society of minds'에서 영감을 받아, 다양한 LLM 에이전트들이 원탁회의(Round Table Conference)를 통해 협력적 추론을 강화하는 프레임워크가 설계되었습니다.
- **MindStorms:** 연구에 따르면 많은 수의 구성원 간의 마인드스톰(MindStorms)이 적은 수의 구성원보다 더 나은 성과를 내며, 더 긴 논의가 짧은 논의보다 더 효과적일 수 있습니다.
- **교사-학습자 역학:** 전문가 LLM이 덜 유능한 LLM에게 힌트나 피드백을 제공하는 인간 튜터링과 유사한 방식도 탐구되고 있습니다.
- **GovSim:** 전략적 상호작용과 협력적 의사결정을 시뮬레이션하며, "모두가 그렇게 한다면 어떻게 될까?"라는 보편화 질문(universalization reasoning)을 도입했을 때 지속 가능한 결과를 도출하는 데 도움이 됨을 발견했습니다.
- **ChatEval:** 텍스트 요약 품질을 개선하기 위해 토론자 에이전트, 다양한 역할 지정, 의사소통 전략을 포함한 다중 에이전트 토론 프레임워크를 사용하는 시스템입니다[Chan et al., 2023].

    
    ![image.png](image%2024.png)
    
<br><br>
## 4.3 Simulating Open-ended Societies

- **개요:** Agentic LLM은 지각, 기억, 추론 능력이 향상되어 사전 역할 할당 없이도 개방형(Open-ended) 시뮬레이션에서 상호작용할 수 있습니다. 이들은 다양한 성격을 가질 수 있습니다 .
<br>
### 4.3.1 SIMULACRA AND SOCIETIES

- **Generative Agents:** [Park et al. 2023]은 25명의 LLM 기반 에이전트가 거주하는 가상 마을을 소개합니다
- **행동 양상:** 에이전트들은 '심즈(The Sims)'의 캐릭터처럼 행동하며 대화를 시작하고, 관계를 형성하고, 정보를 전파하며, 즉흥적인 그룹 활동(예: 발렌타인 파티)을 진행합니다.

    
    ![image.png](image%2025.png)
    
    ![image.png](image%2026.png)
    

- **사회적 패턴의 창발:** 이러한 결과는 동적인 LLM 간 상호작용을 통해 사회적 패턴이 나타날 수 있음을 보여줍니다.
- **대규모 시뮬레이션:**
  - **AgentSociety:** 10,000명 이상의 에이전트를 포함하는 대규모 시뮬레이션으로, 양극화나 재난 충격과 같은 사회적 현상을 연구합니다.
  - **오정보 확산 연구:** [Li et al. 2024]은 다양한 성별, 나이, 성격 특성을 가진 에이전트들을 통해 오정보의 확산을 연구했습니다 .
  - **AgentVerse:** 인간 집단 역학에서 영감을 받아 전문가 에이전트 그룹이 협력하여 개별 합보다 더 큰 성과를 낼 수 있는지 연구하는 다중 에이전트 시스템입니다. 에이전트들은 자원봉사나 동조(conformity)와 같은 행동을 보였습니다.

    
    ![image.png](image%2027.png)
    

- **OASIS:** 최대 100만 명의 LLM 에이전트를 모델링할 수 있는 확장 가능한 소셜 미디어(Twitter/X, Reddit) 시뮬레이터입니다.

    
    ![image.png](image%2028.png)
    
<br>
### 4.3.2 EMERGENT SOCIAL NORMS

- **사회적 규범 연구:** LLM은 자연어 소통 능력을 통해 사회, 관습, 규범의 창발에 대한 다중 에이전트 연구의 기회를 제공합니다.
- **Evolutionary Agent:** RLHF를 넘어 진화적 방법을 통해 다중 에이전트 시스템에서 Agent Alignment을 연구합니다.

    
    ![image.png](image%2029.png)
    

- **규범의 진화:** 적합도(fitness)가 높은(규범에 더 순응하는) 에이전트가 reproduce할 가능성이 높아지며, 전략이 확산되고 점차 안정화되어 새로운 사회적 규범을 형성합니다.
- **관습의 자연 발생:** LLM 간의 국지적(local) 상호작용에서 전역적(global)으로 수용되는 관습이나 규범이 자발적으로 발생할 수 있습니다.
- **메타 규범 (Metanorms):** [Horiguchi et al. 2024]은 악셀로드(Axelrod)의 메타 규범 게임을 기반으로, LLM 에이전트가 대화를 통해 규범을 위반하는 자를 처벌하지 않는 자를 처벌하는 복잡한 사회적 규범(메타 규범)을 형성할 수 있음을 보여주었습니다.
- **문화적/사회적 인식 (CASA):** [Qiu et al. 2024a]은 웹 기반 에이전트 환경에서 LLM 에이전트의 문화적, 사회적 규범 민감도를 평가하는 벤치마크인 CASA를 소개했습니다.
- **협력 메커니즘:** [Zhang et al. 2023a]의 연구에서는 특정 성격 특성(자신감 과잉 등)과 사고 패턴(토론 또는 반성)을 가진 에이전트 사회를 시뮬레이션하여, 동조(conformity)나 합의 도출과 같은 인간 유사 사회적 행동을 관찰했습니다.

    
    ![image.png](image%2030.png)
    
<br>
### 4.3.3 OPEN-WORLD AGENTS

- **무한한 데이터 생성:** Open World 다중 에이전트 상호작용은 제한된 학습 데이터 문제를 해결하고 새로운 상호작용 데이터를 생성하는 것을 목표로 합니다.
- **LLM을 이용한 문제 해결:** LLM이 생성한 문제를 LLM이 해결하는 방식(예: Multi-agent Finetuning)이 연구되고 있습니다.
- **WebArena:** 전자상거래, 소셜 포럼 등 4가지 공통 도메인의 완전한 기능을 갖춘 웹사이트를 포함하는 현실적인 웹 환경으로, 자율 에이전트 구축을 위해 사용됩니다.
- **Balrog & BenchAgents:** 강화학습 환경(Balrog)과 벤치마크 생성(BenchAgents)을 통해 에이전트의 능력을 평가하고 데이터를 생성합니다.
<br><br>
## 4.4 Discussion

### 4.4.1 INTERACTION STUDIES

- **사회적 기능의 기반:** LLM은 학습 과정에서 습득한 대화 능력, 사회적 기능을 바탕으로 상호작용에 참여합니다.

### 4.4.2 USE CASES: EMERGENT BEHAVIOR AND TRAINING DATA

- **새로운 훈련 데이터:** 상호작용하는 에이전트들은 새로운 훈련 데이터를 생성합니다.
- **자기 학습 (Self-learning):** 상호작용하는 Agentic LLM은 강화학습 스타일의 자기 학습을 가능하게 합니다. 현재, OpenAI와 DeepSeek의 추론 모델 훈련에 강화학습이 점점 더 많이 사용되고 있습니다.
- **데이터셋의 한계 극복:** 강화학습에서 에이전트는 세상에서 자신의 행동을 선택하며, 기존 데이터셋에 제한받지 않습니다. 원칙적으로 에이전트는 자신의 행동이 미치는 영향을 포함하여 세상의 완전한 복잡성을 학습할 수 있습니다 .
<br><br>
# In my opinion

- Agent와 Agent간 관계가 학습 데이터로써 활용될 수 있을 것 같다.
- Agent 간 관계로부터 학습할 수 있는 강화학습 프레임워크를 짠다면, SFT없이 agent간 강화학습에 기반하여 사회적 규범을 학습할 수 있지 않을까?
- 또한, agent간 상호작용에 의해서 사회적 규범이 생성된다면, agent 간 사회적 규범에 대해 개발자가 개입할 수 있는 gate를 마련해야할 것 같다.
